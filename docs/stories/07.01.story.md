# Story 07.01: Core Token Calculation Engine with CLI

## Status

| Field                  | Value                       |
|------------------------|-----------------------------|
| Status                 | Completed                   |
| Epic                   | Epic 7: Token Management    |
| Priority               | Critical                    |
| Estimated Story Points | 3                           |
| Jira                   | TBD                         |

<!-- Status tracking and Epic traceability -->
<!-- Enables progress monitoring and Epic dependency validation -->

## Dependencies

**Story Dependencies:**
- Epic 2: Core Engine (validation framework and dependency tracking infrastructure)
- System: Golang tiktoken library or equivalent tokenization library
- System: Existing asset resolution and dependency tracking mechanisms

<!-- Define what this story depends on and what depends on it -->
<!-- Critical for LLM execution order and validation -->

## Story

**As a** Developer,
**I want** to analyze token usage for agent configurations using CLI commands with accurate GPT-4 tokenization,
**so that** I can understand token consumption patterns and avoid the 20% deployment failure rate caused by context limit violations.

<!-- Standard user story format focusing on persona, goal, and business value -->
<!-- Must align with Epic's target users and provide specific value -->

## Acceptance Criteria

1. **CLI Command Implementation**: Command `krci-ai tokens --agent <agent_name>` returns token count for individual agents within 1 second
   - Validation: `time krci-ai tokens --agent pm` completes in <1s with accurate token count
   - File deliverable: `cmd/krci-ai/cmd/tokens.go` with agent-specific token analysis

2. **Project-wide Token Analysis**: Command `krci-ai tokens --all` provides comprehensive token analysis for entire project configuration
   - Validation: `krci-ai tokens --all` returns total token count with breakdown by asset type (agents, tasks, templates, data)
   - File deliverable: `internal/tokens/calculator.go` with project-wide analysis capability

3. **GPT-4 Tokenization Accuracy**: Token calculations match actual GPT-4 consumption within 10% variance (Epic requirement)
   - Validation: Cross-platform testing against actual GPT-4 API token counts using test configurations
   - File deliverable: `internal/tokens/gpt4.go` with tiktoken library integration

4. **Performance Requirements**: Token calculation completes within 3 seconds for projects with 20+ agents
   - Validation: Performance testing with realistic project configurations
   - Command: `time krci-ai tokens --all` on large test project

5. **Error Handling**: CLI provides clear error messages for invalid agents or missing dependencies
   - Validation: `krci-ai tokens --agent nonexistent` returns user-friendly error message
   - File deliverable: Comprehensive error handling implementation

6. **Token Calculation Engine**: Core tokenization engine supports pluggable platform adapters for future Claude/Gemini support
   - Validation: Token engine architecture allows for multiple tokenization backends (Story 07.02 dependency)
   - File deliverable: `internal/tokens/engine.go` with TokenCalculator interface and pluggable architecture

<!-- Specific, testable conditions that define completion -->
<!-- Must include file deliverables and verification commands for LLM validation -->

## Description

This foundational story establishes the core token calculation engine as the first component of Epic 7's token management system. The story implements the essential tokenization infrastructure that will support all subsequent token analysis features, including real-time validation integration, bundle optimization, and multi-platform support.

The token calculation engine serves as the foundation for addressing the Epic's primary goal of reducing token-related deployment failures from 20% to under 5%. By providing developers with immediate token feedback during the design phase, this story enables proactive optimization before costly runtime failures occur.

This implementation focuses on GPT-4 tokenization as the primary use case while establishing an extensible architecture that will support Claude and Gemini platforms in subsequent stories. The CLI interface provides both granular agent-level analysis and comprehensive project-wide token reporting, giving developers the visibility they need for informed decision-making.

<!-- Context explaining why this story exists and its strategic importance -->
<!-- Should provide background for LLM understanding and Epic alignment -->

## Tasks/Subtasks

- [x] **Task 1: Token Calculation Engine Foundation (AC: 6)**
  - [x] Create file: `internal/tokens/engine.go` with TokenCalculator interface
  - [x] Create file: `internal/tokens/tokenizer.go` with pluggable tokenization framework
  - [x] Implement GPT-4 tokenizer: `internal/tokens/gpt4.go` using tiktoken library
  - [x] Create file: `internal/tokens/calculator.go` with asset-aware token calculation
  - [x] Validate architecture: Run `go build ./internal/tokens/...` - Expected: successful compilation

- [x] **Task 2: CLI Command Implementation (AC: 1, 2)**
  - [x] Create file: `cmd/krci-ai/cmd/tokens.go` with CLI command structure
  - [x] Implement `--agent` flag: Individual agent token analysis functionality
  - [x] Implement `--all` flag: Project-wide token calculation functionality
  - [x] Add command registration: Update `cmd/krci-ai/cmd/root.go` to include tokens command
  - [x] Validate CLI: Run `go build ./cmd/krci-ai && ./krci-ai tokens --help` - Expected: help output displayed

- [x] **Task 3: Asset Integration and Dependency Tracking (AC: 1, 2)**
  - [x] Integrate with existing asset discovery: Leverage `internal/assets/discovery.go`
  - [x] Implement dependency resolution: Token calculation includes referenced assets
  - [x] Add asset type breakdown: Separate token counts for agents, tasks, templates, data
  - [x] Create file: `internal/tokens/assets.go` with asset-aware token calculation
  - [x] Validate integration: Run `krci-ai tokens --agent pm` - Expected: token count with dependency breakdown

- [x] **Task 4: Performance Optimization and Caching (AC: 4)**
  - [x] Add concurrent processing: Parallel token calculation for multiple assets
  - [x] Optimize dependency resolution: Avoid redundant asset loading
  - [x] Validate performance: Run `time krci-ai tokens --all` - Expected: <3 seconds completion

- [x] **Task 5: Error Handling and User Experience (AC: 5)**
  - [x] Implement comprehensive error handling: Invalid agent names, missing files, dependency errors
  - [x] Add user-friendly error messages: Clear guidance for common issues
  - [x] Create file: `internal/tokens/errors.go` with token-specific error types
  - [x] Validate error handling: Test various failure scenarios - Expected: clear error messages
  - [x] Add progress indicators: Show progress for large project analysis

- [x] **Task 6: Testing and Validation (AC: 3)**
  - [x] Create file: `internal/tokens/engine_test.go` with comprehensive unit tests
  - [x] Create file: `cmd/krci-ai/cmd/tokens_test.go` with CLI command tests
  - [x] Implement accuracy testing: Compare against actual GPT-4 API token counts
  - [x] Validate accuracy: Run `go test ./internal/tokens/...` - Expected: all tests pass with <10% variance

<!-- LLM-executable implementation plan with atomic tasks and validation -->
<!-- Each task maps to acceptance criteria with specific commands and file paths -->

## Implementation Results

<!-- This section will be populated after story completion -->

<!-- Concrete outcomes and deliverables populated AFTER story completion -->
<!-- Documents actual files created, commands executed, and validation results -->

## QA Checklist

### Functional Testing
- [ ] **CLI Command Execution**: Run `krci-ai tokens --agent pm` - Expected: token count returned in <1 second
- [ ] **Project Analysis**: Run `krci-ai tokens --all` - Expected: comprehensive token breakdown with asset types
- [ ] **Error Handling**: Run `krci-ai tokens --agent invalid` - Expected: clear error message displayed
- [ ] **Help Documentation**: Run `krci-ai tokens --help` - Expected: complete usage documentation

### Performance Testing  
- [ ] **Individual Agent Speed**: Run `time krci-ai tokens --agent pm` - Expected: <1 second execution
- [ ] **Large Project Performance**: Run `time krci-ai tokens --all` on 20+ agent project - Expected: <3 seconds
- [ ] **Memory Usage**: Monitor memory consumption during large project analysis - Expected: reasonable resource usage
- [ ] **Concurrent Access**: Test multiple simultaneous token calculations - Expected: no race conditions

### Accuracy Testing
- [ ] **GPT-4 Tokenization**: Compare `krci-ai tokens` output with actual GPT-4 API counts - Expected: <10% variance
- [ ] **Dependency Tracking**: Verify token counts include all referenced assets - Expected: complete dependency inclusion
- [ ] **Asset Type Breakdown**: Validate separate counts for agents, tasks, templates, data - Expected: accurate categorization
- [ ] **Edge Cases**: Test with empty files, circular dependencies, missing assets - Expected: graceful handling

### Integration Testing
- [ ] **Asset Discovery Integration**: Verify compatibility with existing asset discovery - Expected: seamless integration
- [ ] **CLI Framework Integration**: Test with existing CLI commands and flags - Expected: consistent behavior
- [ ] **Cross-platform Compatibility**: Test on macOS, Linux, Windows - Expected: consistent results
- [ ] **Build Integration**: Verify `make build` includes token functionality - Expected: successful compilation

<!-- Specific verification steps with commands and expected outputs -->
<!-- Enables automated testing and quality validation -->
