# Project Brief: {{project_name}} (Advanced Validation)

> **Target Length**: 2-3 pages maximum
> **Framework**: Advanced validation flow with business framework validation
> **File Location**: MUST be saved as `/docs/prd/project-brief.md` (exact path)
> **Flow Type**: ADVANCED_VALIDATION | **Evidence Level**: {{evidence_confidence}} | **Assumptions**: {{tracked_assumptions}}

---

## Executive Summary

<executive_summary>
{{executive_summary}}

Validation Checkpoint: Problem-Solution Fit Assessment
- Problem validated using {{validation_method}}
- Solution approach validated with {{business_framework}}
- Business value quantified with {{confidence_level}} confidence

Key Assumptions:
- {{assumption_1}} (Confidence: {{confidence_1}}, Evidence: {{evidence_source_1}})
- {{assumption_2}} (Confidence: {{confidence_2}}, Evidence: {{evidence_source_2}})

Validation Methods Applied:
1. Lean Startup Problem-Solution Fit Analysis
2. Business Model Canvas Value Proposition Validation
3. Market Opportunity Assessment with TAM/SAM/SOM

<instructions>
Provide a compelling 3-4 sentence overview combining validated problem, solution approach, and quantified expected outcome.

Example: Our SaaS platform experiences 2,500 password-related support tickets monthly (validated through 6-month support data analysis), consuming 15% of support resources and causing user frustration (confirmed through 25 user interviews). We will implement biometric authentication and social login options to reduce password dependency, targeting 80% reduction in support tickets and $50K annual savings (validated through similar industry implementations). This 3-month initiative serves 10,000+ monthly active users and requires Auth0 integration with a $25K budget (confirmed through vendor quotes and technical assessment).

Advanced Elements:
- All numbers backed by documented evidence sources
- Solution approach validated through business frameworks
- Expected outcomes confirmed through benchmark analysis
- Scope validated through stakeholder interviews and constraint analysis
</instructions>
</executive_summary>

---

## Problem Statement

<problem_statement>
{{problem_statement}}

Validation Checkpoint: Root Cause Analysis
- Problem validated using {{problem_validation_method}}
- Root causes identified with {{root_cause_method}}
- Problem scope boundaries confirmed through {{scope_validation}}
- Impact quantification verified with {{impact_evidence}}

Problem Evidence:
- Primary Evidence: {{primary_evidence}} (Confidence: {{evidence_confidence_1}})
- Supporting Data: {{supporting_data}} (Confidence: {{evidence_confidence_2}})
- Stakeholder Validation: {{stakeholder_input}} (Confidence: {{evidence_confidence_3}})

Validation Methods Available:
1. Six Sigma 5 Whys Root Cause Analysis
2. Impact-Frequency Problem Assessment
3. Stakeholder Problem Validation Interviews

<instructions>
Define the specific pain point driving this project with validated scope boundaries and quantified evidence.

Example: Development teams spend 3-4 hours daily on manual code reviews (validated through time-tracking analysis of 50 developers across 5 teams over 3 months), leading to 15% of total development time lost and delayed feature releases (confirmed through project delivery data analysis). This problem affects 85% of development teams according to industry survey data and costs organizations $150K annually per 20-developer team (calculation validated through comparable industry benchmarks). Focus on code review workflow optimization only, excluding code quality policy management or development process changes (scope confirmed through stakeholder interviews).

Advanced Evidence Requirements:
- Quantified problem metrics with data source attribution
- User research findings with sample sizes and methodologies
- Industry benchmark comparisons with credible sources
- Stakeholder interview validation with diverse role representation
- Historical data analysis showing problem persistence and trends
</instructions>
</problem_statement>

---

## Opportunity

<opportunity>
{{opportunity}}

Validation Checkpoint: Value Proposition Analysis
- Business value validated using {{value_validation_method}}
- Market opportunity sized with {{market_analysis_method}}
- Competitive advantage confirmed through {{competitive_analysis}}
- ROI calculations validated with {{roi_validation_method}}

Value Evidence:
- Financial Analysis: {{financial_evidence}} (Method: {{financial_method}}, Confidence: {{financial_confidence}})
- Market Research: {{market_evidence}} (Source: {{market_source}}, Confidence: {{market_confidence}})
- Competitive Analysis: {{competitive_evidence}} (Scope: {{competitive_scope}}, Confidence: {{competitive_confidence}})

Validation Methods Available:
1. Value Proposition Canvas Fit Assessment
2. Business Model Canvas Value Validation
3. ROI Calculation with Multi-Method Verification

<instructions>
Provide quantified business value plus validated solution approach with evidence-based projections.

Example: Reducing manual code review time by 70% would save $105K annually per 20-developer team (calculation validated through industry salary benchmarks and productivity studies), improve feature delivery speed by 40% (confirmed through similar tool implementations at comparable organizations), and increase developer satisfaction by 25% (based on peer organization case studies). Implement AI-powered code review assistant integrating with existing GitHub workflows to provide automated security analysis, code quality recommendations, and reviewer prioritization (solution approach validated through technical feasibility assessment and vendor demonstrations).

Advanced Value Requirements:
- Business value quantified with multiple calculation methods
- Cost savings validated through industry benchmarks and internal data
- Revenue impact projections based on comparable implementations
- Competitive advantage analysis with market positioning assessment
- Solution feasibility confirmed through technical and vendor validation
</instructions>
</opportunity>

---

## Target Users

<target_users>
{{target_users}}

Validation Checkpoint: User Segment Analysis
- User segments validated using {{user_validation_method}}
- Jobs-to-be-Done analysis completed with {{jobs_evidence}}
- User journey mapping verified through {{journey_validation}}
- Market sizing confirmed with {{sizing_evidence}}

User Evidence:
- Primary Research: {{user_research}} (Sample: {{sample_size}}, Method: {{research_method}}, Confidence: {{user_confidence}})
- Usage Analytics: {{analytics_data}} (Period: {{data_period}}, Sample: {{analytics_sample}}, Confidence: {{analytics_confidence}})
- Market Data: {{market_research}} (Source: {{market_source}}, Date: {{market_date}}, Confidence: {{market_confidence}})

Validation Methods Available:
1. Jobs-to-be-Done User Validation with Importance/Satisfaction Scoring
2. Design Thinking User Journey Mapping with Pain Point Quantification
3. Persona Demographic Validation with Market Sizing

<instructions>
Provide specific user segments validated through research with usage patterns, demographics, and evidence-based sizing.

Example: Software development teams (validated market size: 450,000 teams globally based on Stack Overflow Developer Survey and GitHub Enterprise data) with 20-500 developers who conduct code reviews 3+ times daily (confirmed through usage pattern analysis of 100 development teams). Primary segment: senior developers and team leads aged 28-45 who spend 25-30% of their time on code review activities (validated through time-tracking study of 200 developers across 15 organizations). User jobs-to-be-done analysis reveals core job: When reviewing code, I want to quickly identify security issues and quality problems so I can maintain high standards while not becoming a development bottleneck (importance: 9.2/10, current satisfaction: 4.1/10, opportunity score: 14.3/15 based on survey of 150 senior developers).

Advanced User Requirements:
- User volume quantified with credible market research sources
- Demographics validated through multiple research sources
- Usage patterns confirmed through analytics and user observation
- Segment prioritization based on revenue potential and solution fit
- Jobs-to-be-Done analysis with importance and satisfaction scoring
- User journey validation with pain point impact quantification
</instructions>
</target_users>

---

## Success Metrics

<success_metrics>
{{success_metrics}}

Validation Checkpoint: Metrics Quality Assessment
- SMART criteria validation completed for all metrics
- OKR alignment confirmed with {{okr_alignment_evidence}}
- Leading/lagging indicator balance verified
- Measurement feasibility validated with {{measurement_validation}}

Metrics Evidence:
- Baseline Data: {{baseline_metrics}} (Source: {{baseline_source}}, Period: {{baseline_period}}, Confidence: {{baseline_confidence}})
- Industry Benchmarks: {{benchmark_data}} (Source: {{benchmark_source}}, Date: {{benchmark_date}}, Confidence: {{benchmark_confidence}})
- Historical Performance: {{historical_data}} (Period: {{historical_period}}, Sample: {{historical_sample}}, Confidence: {{historical_confidence}})

Validation Methods Available:
1. SMART Criteria Assessment with Scoring Matrix
2. OKR Alignment Validation with Strategic Goal Mapping
3. Leading/Lagging Indicator Analysis with Predictive Relationship Assessment

<instructions>
Provide validated success metrics with SMART criteria assessment and evidence-based targets.

Example: Reduce code review time by 70% within 6 months (Specific: manual review time reduction, Measurable: current average 3.2 hours/day to <1 hour/day based on time-tracking analysis, Achievable: confirmed through similar AI tool implementations showing 60-80% reduction, Relevant: aligns with developer productivity OKR and engineering efficiency goals, Time-bound: 6-month implementation with monthly measurement). Improve security vulnerability detection by 60% measured through monthly security audit results (baseline: 23 vulnerabilities/month missed in manual reviews based on 6-month retrospective analysis, target: <10 vulnerabilities/month based on AI-assisted tool benchmarks). Achieve 80% developer adoption within 3 months measured through GitHub integration usage analytics (baseline: 0%, industry benchmark: 70-85% adoption for development productivity tools based on adoption studies).

Advanced Metrics Requirements:
- All metrics assessed using SMART criteria with documented scoring
- Baseline data collected and validated with multiple sources
- Targets calibrated using industry benchmarks and comparable implementations
- Measurement systems identified and validated for feasibility
- Leading indicators defined to predict lagging outcome achievement
- OKR alignment confirmed with organizational strategic goals
</instructions>
</success_metrics>

---

## Constraints

<constraints>
{{constraints}}

Validation Checkpoint: Constraint Analysis
- Resource constraints validated with {{resource_validation}}
- Technical constraints confirmed through {{technical_validation}}
- Business constraints verified with {{business_validation}}
- Timeline feasibility assessed using {{timeline_validation}}

Constraint Evidence:
- Resource Analysis: {{resource_evidence}} (Method: {{resource_method}}, Confidence: {{resource_confidence}})
- Technical Assessment: {{technical_evidence}} (Source: {{technical_source}}, Confidence: {{technical_confidence}})
- Business Validation: {{business_evidence}} (Stakeholder: {{business_stakeholder}}, Confidence: {{business_confidence}})

<instructions>
Resource, technical, and business factors that limit the solution, validated with evidence and stakeholder confirmation.

Example: Must integrate with existing Auth0 setup (technical constraint confirmed through architecture review and vendor confirmation), 6-month timeline driven by regulatory compliance deadline (business constraint validated through legal team consultation), $150K budget allocation confirmed through financial planning process (resource constraint validated through budget approval documentation), maximum 3 developers assigned based on team capacity analysis (resource constraint confirmed through engineering management review). Assumes current mobile app architecture supports biometric APIs based on technical assessment (assumption validated through proof-of-concept implementation) and 75% of users have biometric-capable devices based on user analytics analysis (assumption validated through device usage data from past 12 months).

Advanced Constraint Requirements:
- Resource constraints validated through capacity planning and budget analysis
- Technical constraints confirmed through architecture review and feasibility assessment
- Business constraints verified with stakeholder interviews and compliance review
- Timeline constraints validated through project estimation and dependency analysis
- Assumptions documented with evidence sources and confidence levels
</instructions>
</constraints>

---

## Key Risks

<key_risks>
{{key_risks}}

Validation Checkpoint: Risk Assessment Analysis
- Risk impact assessment completed using {{risk_assessment_method}}
- Risk probability analysis validated with {{probability_evidence}}
- Mitigation strategies identified and validated
- Risk monitoring plan established with {{monitoring_approach}}

Risk Evidence:
- Historical Risk Data: {{risk_history}} (Source: {{risk_source}}, Period: {{risk_period}}, Confidence: {{risk_confidence}})
- Industry Risk Analysis: {{industry_risks}} (Source: {{industry_source}}, Scope: {{industry_scope}}, Confidence: {{industry_confidence}})
- Expert Assessment: {{expert_input}} (Expert: {{expert_source}}, Method: {{expert_method}}, Confidence: {{expert_confidence}})

Risk Assessment Methods Available:
1. Risk Impact-Probability Matrix with Quantified Scoring
2. Industry Benchmark Risk Analysis with Peer Comparison
3. Expert Panel Risk Assessment with Structured Evaluation

<instructions>
Major risks validated through evidence and expert assessment with quantified impact and probability estimates.

Example: User adoption resistance (HIGH impact, MEDIUM probability): Senior developers may resist AI-assisted tools based on past automation concerns. Evidence: Survey of 100 senior developers shows 35% initial resistance to AI coding tools, but 78% adoption after 3-month trial period in comparable organizations. Mitigation: Implement gradual rollout with developer champion program and productivity showcase (strategy validated through change management consultant review). Integration complexity (MEDIUM impact, HIGH probability): GitHub Enterprise API integration may require custom authentication handling based on initial technical assessment. Evidence: Similar integrations required 2-4 weeks additional development time in 60% of comparable implementations according to vendor case studies. Mitigation: Allocate 4-week buffer for integration testing and custom development (timeline validated through technical lead estimation).

Advanced Risk Requirements:
- Risk impact quantified with specific metrics and evidence sources
- Risk probability based on historical data and expert assessment
- Mitigation strategies validated through case studies and expert consultation
- Risk monitoring plan with specific triggers and measurement approaches
- Evidence sources documented with quality assessment and confidence levels
</instructions>
</key_risks>

---

## Advanced Validation Summary

<validation_summary>

### Validation Framework Applied

- Primary Frameworks: {{primary_frameworks_used}}
- Validation Confidence: {{overall_validation_confidence}}%
- Evidence Quality Score: {{evidence_quality_score}}/100
- Assumption Risk Level: {{assumption_risk_level}}

### Business Framework Integration

- Problem Validation: {{problem_framework}} (Score: {{problem_score}}/10)
- User Validation: {{user_framework}} (Score: {{user_score}}/10)
- Metrics Validation: {{metrics_framework}} (Score: {{metrics_score}}/10)
- Value Validation: {{value_framework}} (Score: {{value_score}}/10)
</validation_summary>

<supporting_documentation>

### Supporting Documentation

- Project Context: `/docs/prd/project-context.md`
- Assumption Tracker: `/docs/prd/brief-assumptions.md`
- Evidence Library: `/docs/prd/brief-evidence.md`
- Validation Reports: `/docs/prd/brief-validation-*.md`
</supporting_documentation>

---

## SDLC Framework Information

<sdlc_framework>
Dependencies: Project context gathering and validation completion
Output Location: This Project Brief MUST be saved as `/docs/prd/project-brief.md`
Downstream Enablement: Enables enhanced PRD creation with validated foundation
Flow Type: ADVANCED_VALIDATION for evidence-based decision making

<instructions>
This Advanced Project Brief provides comprehensive foundation for:
- PRD Problem/Opportunity section (validated with evidence)
- PRD Target Users & Use Cases (research-backed segments)
- PRD Goals/Measurable Outcomes (SMART-validated metrics)
- PRD scope and constraint definition (stakeholder-validated)

Directory Structure (Advanced Flow):
/docs/
├── prd/                          # Product vision & requirements (enhanced)
│   ├── project-context.md        # Context gathering results
│   ├── project-brief.md          # Project vision & strategy (THIS FILE - ADVANCED)
│   ├── brief-assumptions.md      # Assumption tracking and validation status
│   ├── brief-evidence.md         # Evidence library with confidence levels
│   ├── brief-validation-*.md     # Business framework validation reports
│   └── prd.md                    # Product requirements (ENHANCED BY VALIDATION)
├── epics/                        # High-level features
├── stories/                      # User stories
├── architecture/                 # System design
└── tests/                        # Quality validation
</instructions>
</sdlc_framework>

---

## Upgrade from Standard Flow

<upgrade_summary>
Migration Process: This advanced brief was {{migration_status}}:
- Original Brief: {{original_brief_status}}
- Enhancement Trigger: {{enhancement_reason}}
- Validation Added: {{validation_components_added}}
- Confidence Improvement: {{confidence_change}}

Advanced Value: {{advanced_value_summary}}
</upgrade_summary>
